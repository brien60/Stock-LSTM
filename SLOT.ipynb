{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a214f642",
   "metadata": {},
   "source": [
    "SLOT (Self-supervised Learning of Tweets for Capturing Multi-level Price Trends) aims to address\n",
    "1. the sparsity of tweets, with the number of tweets being heavily biased towards the most popular stocks.\n",
    "2. the fact that tweets have noisy information that are often irrelevant to the actual stock movement.\n",
    "\n",
    "The first problem was addressed by having SLOT learn the stock and tweet embeddings in the same vector space through self-supervised learning. This allows the use of any tweet for even unpopular stocks.\n",
    "\n",
    "To tackle the second problem, SLOT uses tweets to learn multi-level relationships between stocks, rather than using them as direct evidence for stock prediction (e.g. positive sentiment = up)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dccb983",
   "metadata": {},
   "source": [
    "## Attention LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e97e35be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class ALSTM:\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.ln = nn.Linear(hidden_size, hidden_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.u = nn.Parameter(data=torch.randn(hidden_size))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len, input_size)\n",
    "        # output: (batch, seq_len, hidden_size)\n",
    "        # h_n, c_n : (num_layers, batch, hidden_size)\n",
    "        output, h_n, c_n = self.lstm(x)\n",
    "        output = self.tanh(self.ln(output))\n",
    "\n",
    "        # query: u, key: output, values: output\n",
    "        attn_scores = torch.matmul(output, self.u) # (batch, seq_len, hidden_size) @ (hidden_size) -> (batch, seq_len)\n",
    "        weights = attn_scores / attn_scores.sum(dim=1, keepdim=True)\n",
    "        weights = weights.unsqueeze(dim=-1) # (batch, seq_len, 1)\n",
    "        \n",
    "        # (batch, seq_len, 1) * (batch, seq_len, hidden_size) -> (batch, seq_len, hidden_size)\n",
    "        # (batch, seq_len, hidden_size) -> (batch, hidden_size)\n",
    "        h_attn = (weights * output).sum(dim=1)\n",
    "\n",
    "        # (batch, hidden_size) || (batch, hidden_size) -> (batch, 2*hidden_size)\n",
    "        h_out = torch.cat((h_n[0], h_attn), dim=1) # both the general summary and the attention\n",
    "\n",
    "        return h_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8313c695",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SLOT:\n",
    "    def __init__(self, input_size, hidden_size, output_size = 1):\n",
    "        self.ln_1 = nn.Linear(3*input_size, 3*input_size)\n",
    "        self.alstm = ALSTM(input_size=3*input_size, hidden_size=hidden_size)\n",
    "        self.ln_f = nn.Linear(hidden_size*2, output_size)\n",
    "\n",
    "    def forward(self, features, global_trend, local_trend):\n",
    "        # features, global_trend, local_trend: (batch, seq_len, input_size)\n",
    "        final_input = torch.cat((features, global_trend, local_trend), dim=-1) # (batch, 3*input_size)\n",
    "        finall_input = self.ln_1(final_input)\n",
    "        h_out = self.alstm(final_input) # (batch, 2*hidden_size)\n",
    "        y_pred = self.ln_f(h_out) # (batch, output_size)\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00548375",
   "metadata": {},
   "source": [
    "## Self-supervised Learning of Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538d37b0",
   "metadata": {},
   "source": [
    "The goal is to learn tweet (h_e) and stock (h_s) embeddings in the same semantic space, that is, learning the embeddings together such that one embedding can be used to query for the other. \n",
    "- a stock embedding and the embedding of tweet relevant to it are close together (higher dot product)\n",
    "- solves problem of tweet sparsity; the model can associate stocks with tweets that don't directly mention it as long as they are close in vector space.\n",
    "\n",
    "This was done by training for stock identification: predict the mentioned stock in a tweet when the stock symbol is masked.\n",
    "\n",
    "First, every tweet is tokenized with Sentence Piece. Next, the tokens that correspond to the stock the tweet mentions are masked with the special token MASK.\n",
    "- \"Thank you Apple for the new iPhone.\" -> \"Thank you [MASK] for the new iPhone.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d17860",
   "metadata": {},
   "source": [
    "### Stock Identification Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2a2c7c",
   "metadata": {},
   "source": [
    "Use a BiLSTM (need to understand the context on both sides of the mask token).\n",
    "- Using a transformer risks overfitting.\n",
    "\n",
    "The stock embedding is a learnable parameter. \n",
    "\n",
    "The hidden state vector generated at the masked token is used as the tweet embedding because it\n",
    "- captures the immediate left (via the forward LSTM) and right context (via the backward LSTM) of the tweet, making it exactly what we need for stock identification,\n",
    "- and it is the part of the tweet that most connects to mentioned stock.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cda0f499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 lines written\n",
      "200000 lines written\n",
      "300000 lines written\n",
      "324573 lines written\n",
      "All tweets written\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path   \n",
    "import json\n",
    "\n",
    "data_dir = Path(\"data/bigdata22\")\n",
    "tweet_dir = data_dir / \"tweet\"\n",
    "\n",
    "\n",
    "tweet_files_list = list(tweet_dir.rglob(\"*/*\"))\n",
    "\n",
    "json_file = \"all_tweets.jsonl\"\n",
    "\n",
    "buffer = []\n",
    "buffer_size = 100_000\n",
    "lines = 0\n",
    "\n",
    "with open(json_file, \"w\", encoding=\"utf-8\") as out:\n",
    "    for tweet_file in tweet_files_list:\n",
    "        with open(tweet_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                tweet = json.loads(line)\n",
    "\n",
    "                json_tweet = {\n",
    "                    \"stock\": tweet_file.parent.name,\n",
    "                    \"tweet\": tweet[\"text\"].replace(\"\\n\", \" \")\n",
    "                }\n",
    "\n",
    "                buffer.append(json.dumps(json_tweet))\n",
    "\n",
    "                if len(buffer) >= buffer_size:\n",
    "                    out.write(\"\\n\".join(buffer) + \"\\n\")\n",
    "                    lines += len(buffer)\n",
    "\n",
    "                    buffer.clear()\n",
    "\n",
    "                    print(f\"{lines} lines written\")\n",
    "\n",
    "    if buffer:\n",
    "        lines += len(buffer)\n",
    "        out.write(\"\\n\".join(buffer) + \"\\n\")\n",
    "        print(f\"{lines} lines written\")\n",
    "\n",
    "print(\"All tweets written\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68b7df85",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = json_file\n",
    "output_file = \"tweets_for_sp.txt\"\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f, open(output_file, \"w\", encoding=\"utf-8\") as out:\n",
    "    for line in f:\n",
    "        tweet = json.loads(line)\n",
    "        out.write(tweet[\"tweet\"] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a7922d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as sp\n",
    "\n",
    "spm_file = \"spm/slot_tweet_spm\"\n",
    "\n",
    "sp.SentencePieceTrainer.train(\n",
    "    input=output_file,\n",
    "    model_prefix=spm_file,\n",
    "    vocab_size=16_000,\n",
    "    model_type=\"unigram\",\n",
    "    character_coverage=1.0,\n",
    "    input_sentence_size=lines,\n",
    "    shuffle_input_sentence=True,\n",
    "    user_defined_symbols=[\"<MASK>\", \"<PAD>\"]\n",
    ")\n",
    "\n",
    "spm_file += \".model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142bd4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11562, 212, 1434, 762, 96, 6, 4567, 1810, 384, 5, 102, 671, 63, 5, 8032, 15, 382, 931, 32, 83, 11784, 8476, 6, 3, 259, 135, 1034, 15, 3077, 3845, 842, 29, 41, 39, 32, 520, 1244, 3498, 2494, 96, 1125, 457, 9]\n",
      "['▁weather', 'ly', '▁asset', '▁management', '▁has', '▁', 'upped', '▁boeing', '▁co', '▁$', 'ba', '▁stake', '▁by', '▁$', '333', ',', '9', '14', ';', '▁as', '▁honeywell', '▁intl', '▁', '<MASK>', '▁share', '▁price', '▁rose', ',', '▁holder', '▁pic', 'te', 't', '▁&', 'amp', ';', '▁c', 'ie', '▁europe', '▁sa', '▁has', '▁raised', '▁holding', '▁URL']\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as sp\n",
    "\n",
    "slot_spm = sp.SentencePieceProcessor()\n",
    "slot_spm.load(spm_file)\n",
    "\n",
    "import re\n",
    "\n",
    "tweet = \"$aapl laser game controller?  URL $mvis disruptive tech ..? $qqq $mu $goog $bbry $sne $txn $fb $twtr $msft $himx $iwm\"\n",
    "stock_name = \"AAPL\"\n",
    "\n",
    "pattern = rf\"\\${stock_name}(?=\\s|$|\\W)\"\n",
    "masked_tweet = re.sub(pattern, \"<MASK>\", tweet, flags=re.IGNORECASE)\n",
    "\n",
    "print(slot_spm.encode(masked_tweet))\n",
    "print(slot_spm.encode(masked_tweet, out_type=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a9dd71c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AAPL': 0,\n",
       " 'AEP': 1,\n",
       " 'AGFS': 2,\n",
       " 'AMGN': 3,\n",
       " 'AMZN': 4,\n",
       " 'BA': 5,\n",
       " 'BAC': 6,\n",
       " 'C': 7,\n",
       " 'CAT': 8,\n",
       " 'CMCSA': 9,\n",
       " 'CODI': 10,\n",
       " 'CSCO': 11,\n",
       " 'CVX': 12,\n",
       " 'D': 13,\n",
       " 'DIS': 14,\n",
       " 'DUK': 15,\n",
       " 'EXC': 16,\n",
       " 'GD': 17,\n",
       " 'GE': 18,\n",
       " 'GMRE': 19,\n",
       " 'GOOG': 20,\n",
       " 'HD': 21,\n",
       " 'HON': 22,\n",
       " 'INTC': 23,\n",
       " 'JNJ': 24,\n",
       " 'JPM': 25,\n",
       " 'KO': 26,\n",
       " 'LMT': 27,\n",
       " 'MA': 28,\n",
       " 'MCD': 29,\n",
       " 'MDT': 30,\n",
       " 'MMM': 31,\n",
       " 'MO': 32,\n",
       " 'MRK': 33,\n",
       " 'MSFT': 34,\n",
       " 'NEE': 35,\n",
       " 'ORCL': 36,\n",
       " 'PCG': 37,\n",
       " 'PM': 38,\n",
       " 'PPL': 39,\n",
       " 'REX': 40,\n",
       " 'SO': 41,\n",
       " 'SRE': 42,\n",
       " 'T': 43,\n",
       " 'UPS': 44,\n",
       " 'V': 45,\n",
       " 'VZ': 46,\n",
       " 'WFC': 47,\n",
       " 'WMT': 48,\n",
       " 'XOM': 49}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_names = [stock.name for stock in list(tweet_dir.rglob(\"*\")) if stock.is_dir()]\n",
    "stock_ids = [i for i in range(len(stock_names))]\n",
    "stock_name_to_ids = dict(zip(stock_names, stock_ids))\n",
    "stock_name_to_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "26eb8024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_id = slot_spm.piece_to_id(\"<MASK>\")\n",
    "pad_id = slot_spm.piece_to_id(\"<PAD>\")\n",
    "\n",
    "mask_id, pad_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4ccb7e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AT_USER the #fed like the #msm, #financialmedia is an extension of the #dnc. $aaple was involved in price manipulation with them on jan 2nd when AT_USER gave false guidance, stripping $trillions in price. it’s intention to disrupt economy AT_USER was strengthening. #secfraud #voterid URL'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slot_spm.decode([6, 12, 11, 10, 13, 16, 7, 2672, 76, 16, 7, 474, 42, 15, 7, 2799, 6866, 26, 150, 2852, 24, 16, 7, 56, 3033, 8, 5, 60, 123, 152, 4198, 23, 135, 8221, 38, 421, 27, 1960, 100, 778, 195, 6, 12, 11, 10, 13, 2139, 4978, 2126, 15, 6, 14, 2933, 3122, 5, 2247, 23, 135, 8, 37, 36, 14, 10584, 17, 7515, 2232, 6, 12, 11, 10, 13, 152, 9802, 68, 8, 7, 5070, 7913, 7, 5190, 1811, 56, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfe021e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 lines written\n",
      "200000 lines written\n",
      "300000 lines written\n",
      "324063 lines written\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "tokens_file = \"all_tweets_tokenized.jsonl\"\n",
    "bad_data_file = \"bad_data.jsonl\"\n",
    "\n",
    "buffer = []\n",
    "buffer_size = 100_000\n",
    "lines = 0\n",
    "\n",
    "\n",
    "with open(json_file, \"r\", encoding=\"utf-8\") as f, open(tokens_file, \"w\", encoding=\"utf-8\") as o, open(bad_data_file, \"w\", encoding=\"utf-8\") as b:\n",
    "    for line in f:\n",
    "\n",
    "        entry = json.loads(line)\n",
    "\n",
    "        stock_name = entry[\"stock\"]\n",
    "        tweet = entry[\"tweet\"]\n",
    "        \n",
    "        \n",
    "        patterns = [\n",
    "            rf\"\\${stock_name}(?=\\s|$|\\W)\", # strict match\n",
    "            rf\"\\${stock_name}\" # loose match\n",
    "        ]\n",
    "\n",
    "        success = False\n",
    "        for pattern in patterns:\n",
    "            masked_tweet = re.sub(pattern, \"<MASK>\", tweet, flags=re.IGNORECASE)\n",
    "            masked_tweet_tokenized = slot_spm.encode(masked_tweet)\n",
    "\n",
    "            if mask_id in masked_tweet_tokenized:\n",
    "                mask_idx = masked_tweet_tokenized.index(mask_id)\n",
    "                success = True\n",
    "                break\n",
    "\n",
    "        if not success:\n",
    "            bad_entry = {\n",
    "                \"stock\": stock_name,\n",
    "                \"tweet\": slot_spm.decode(masked_tweet_tokenized)\n",
    "            }\n",
    "            b.write(json.dumps(bad_entry) + \"\\n\")\n",
    "            continue\n",
    "\n",
    "\n",
    "\n",
    "        tokenized_tweet = {\n",
    "            \"tweet\": masked_tweet_tokenized,\n",
    "            \"stock_id\": stock_name_to_ids[stock_name],\n",
    "            \"mask_idx\": mask_idx\n",
    "        }\n",
    "\n",
    "\n",
    "        # tokenized_line = \" \".join(str(id) for id in tokenized_line) + \"\\n\"\n",
    "        buffer.append(json.dumps(tokenized_tweet))\n",
    "        \n",
    "        if len(buffer) >= buffer_size:\n",
    "            o.write(\"\\n\".join(buffer) + \"\\n\")\n",
    "            lines += len(buffer)\n",
    "            buffer.clear()\n",
    "            \n",
    "            print(f\"{lines} lines written\")\n",
    "\n",
    "    if buffer:\n",
    "        o.write(\"\\n\".join(buffer) + \"\\n\")\n",
    "        lines += len(buffer)\n",
    "        print(f\"{lines} lines written\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "413f3031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  ...],\n",
       " [1,\n",
       "  34,\n",
       "  14,\n",
       "  1,\n",
       "  322,\n",
       "  310,\n",
       "  303,\n",
       "  303,\n",
       "  42,\n",
       "  42,\n",
       "  42,\n",
       "  42,\n",
       "  42,\n",
       "  1,\n",
       "  33,\n",
       "  18,\n",
       "  16,\n",
       "  23,\n",
       "  78,\n",
       "  78,\n",
       "  78,\n",
       "  58,\n",
       "  16,\n",
       "  66,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  35,\n",
       "  73,\n",
       "  34,\n",
       "  48,\n",
       "  1,\n",
       "  1,\n",
       "  36,\n",
       "  39,\n",
       "  47,\n",
       "  39,\n",
       "  11,\n",
       "  15,\n",
       "  60,\n",
       "  28,\n",
       "  8,\n",
       "  1,\n",
       "  24,\n",
       "  27,\n",
       "  13,\n",
       "  16,\n",
       "  16,\n",
       "  9,\n",
       "  24,\n",
       "  16,\n",
       "  79,\n",
       "  16,\n",
       "  35,\n",
       "  19,\n",
       "  31,\n",
       "  54,\n",
       "  20,\n",
       "  13,\n",
       "  20,\n",
       "  16,\n",
       "  36,\n",
       "  10,\n",
       "  8,\n",
       "  1,\n",
       "  1,\n",
       "  34,\n",
       "  17,\n",
       "  1,\n",
       "  16,\n",
       "  1,\n",
       "  46,\n",
       "  32,\n",
       "  16,\n",
       "  15,\n",
       "  30,\n",
       "  61,\n",
       "  2,\n",
       "  23,\n",
       "  32,\n",
       "  24,\n",
       "  40,\n",
       "  46,\n",
       "  16,\n",
       "  1,\n",
       "  16,\n",
       "  4,\n",
       "  24,\n",
       "  7,\n",
       "  19,\n",
       "  12,\n",
       "  20,\n",
       "  16,\n",
       "  12,\n",
       "  79,\n",
       "  13,\n",
       "  51,\n",
       "  13,\n",
       "  27,\n",
       "  1,\n",
       "  62,\n",
       "  11,\n",
       "  40,\n",
       "  40,\n",
       "  40,\n",
       "  40,\n",
       "  40,\n",
       "  40,\n",
       "  40,\n",
       "  40,\n",
       "  40,\n",
       "  40,\n",
       "  40,\n",
       "  40,\n",
       "  12,\n",
       "  10,\n",
       "  16,\n",
       "  16,\n",
       "  27,\n",
       "  16,\n",
       "  13,\n",
       "  13,\n",
       "  55,\n",
       "  1,\n",
       "  88,\n",
       "  34,\n",
       "  16,\n",
       "  24,\n",
       "  16,\n",
       "  16,\n",
       "  35,\n",
       "  35,\n",
       "  57,\n",
       "  72,\n",
       "  2,\n",
       "  7,\n",
       "  1,\n",
       "  16,\n",
       "  41,\n",
       "  1,\n",
       "  1,\n",
       "  37,\n",
       "  8,\n",
       "  14,\n",
       "  54,\n",
       "  28,\n",
       "  1,\n",
       "  16,\n",
       "  1,\n",
       "  3,\n",
       "  12,\n",
       "  14,\n",
       "  34,\n",
       "  2,\n",
       "  26,\n",
       "  12,\n",
       "  1,\n",
       "  70,\n",
       "  1,\n",
       "  6,\n",
       "  3,\n",
       "  17,\n",
       "  31,\n",
       "  17,\n",
       "  45,\n",
       "  2,\n",
       "  16,\n",
       "  16,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  55,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  4,\n",
       "  16,\n",
       "  75,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  54,\n",
       "  23,\n",
       "  59,\n",
       "  28,\n",
       "  30,\n",
       "  1,\n",
       "  30,\n",
       "  17,\n",
       "  35,\n",
       "  16,\n",
       "  20,\n",
       "  10,\n",
       "  38,\n",
       "  28,\n",
       "  18,\n",
       "  24,\n",
       "  12,\n",
       "  13,\n",
       "  1,\n",
       "  16,\n",
       "  21,\n",
       "  42,\n",
       "  1,\n",
       "  12,\n",
       "  86,\n",
       "  3,\n",
       "  1,\n",
       "  16,\n",
       "  1,\n",
       "  1,\n",
       "  48,\n",
       "  16,\n",
       "  37,\n",
       "  16,\n",
       "  16,\n",
       "  2,\n",
       "  6,\n",
       "  7,\n",
       "  15,\n",
       "  28,\n",
       "  9,\n",
       "  16,\n",
       "  9,\n",
       "  43,\n",
       "  30,\n",
       "  15,\n",
       "  48,\n",
       "  27,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  1,\n",
       "  1,\n",
       "  29,\n",
       "  3,\n",
       "  10,\n",
       "  21,\n",
       "  21,\n",
       "  7,\n",
       "  1,\n",
       "  49,\n",
       "  8,\n",
       "  15,\n",
       "  1,\n",
       "  10,\n",
       "  8,\n",
       "  3,\n",
       "  11,\n",
       "  50,\n",
       "  4,\n",
       "  16,\n",
       "  38,\n",
       "  16,\n",
       "  16,\n",
       "  17,\n",
       "  17,\n",
       "  32,\n",
       "  1,\n",
       "  48,\n",
       "  51,\n",
       "  61,\n",
       "  6,\n",
       "  14,\n",
       "  10,\n",
       "  33,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  66,\n",
       "  2,\n",
       "  23,\n",
       "  27,\n",
       "  13,\n",
       "  16,\n",
       "  1,\n",
       "  60,\n",
       "  17,\n",
       "  13,\n",
       "  23,\n",
       "  16,\n",
       "  19,\n",
       "  78,\n",
       "  78,\n",
       "  3,\n",
       "  18,\n",
       "  11,\n",
       "  20,\n",
       "  20,\n",
       "  47,\n",
       "  12,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  33,\n",
       "  22,\n",
       "  16,\n",
       "  1,\n",
       "  21,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  25,\n",
       "  26,\n",
       "  9,\n",
       "  2,\n",
       "  1,\n",
       "  11,\n",
       "  3,\n",
       "  1,\n",
       "  8,\n",
       "  8,\n",
       "  13,\n",
       "  3,\n",
       "  10,\n",
       "  1,\n",
       "  1,\n",
       "  33,\n",
       "  7,\n",
       "  1,\n",
       "  35,\n",
       "  13,\n",
       "  21,\n",
       "  16,\n",
       "  24,\n",
       "  6,\n",
       "  23,\n",
       "  18,\n",
       "  5,\n",
       "  1,\n",
       "  35,\n",
       "  1,\n",
       "  10,\n",
       "  12,\n",
       "  9,\n",
       "  38,\n",
       "  29,\n",
       "  21,\n",
       "  22,\n",
       "  62,\n",
       "  3,\n",
       "  3,\n",
       "  16,\n",
       "  1,\n",
       "  13,\n",
       "  23,\n",
       "  45,\n",
       "  20,\n",
       "  19,\n",
       "  35,\n",
       "  35,\n",
       "  16,\n",
       "  1,\n",
       "  1,\n",
       "  7,\n",
       "  27,\n",
       "  14,\n",
       "  4,\n",
       "  1,\n",
       "  12,\n",
       "  1,\n",
       "  14,\n",
       "  16,\n",
       "  76,\n",
       "  1,\n",
       "  1,\n",
       "  72,\n",
       "  34,\n",
       "  1,\n",
       "  2,\n",
       "  11,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  1,\n",
       "  1,\n",
       "  21,\n",
       "  1,\n",
       "  43,\n",
       "  2,\n",
       "  13,\n",
       "  13,\n",
       "  3,\n",
       "  1,\n",
       "  6,\n",
       "  16,\n",
       "  56,\n",
       "  16,\n",
       "  10,\n",
       "  31,\n",
       "  12,\n",
       "  1,\n",
       "  30,\n",
       "  12,\n",
       "  16,\n",
       "  1,\n",
       "  45,\n",
       "  5,\n",
       "  1,\n",
       "  4,\n",
       "  16,\n",
       "  7,\n",
       "  1,\n",
       "  1,\n",
       "  6,\n",
       "  1,\n",
       "  16,\n",
       "  1,\n",
       "  4,\n",
       "  1,\n",
       "  32,\n",
       "  5,\n",
       "  1,\n",
       "  6,\n",
       "  1,\n",
       "  28,\n",
       "  51,\n",
       "  1,\n",
       "  1,\n",
       "  16,\n",
       "  1,\n",
       "  1,\n",
       "  16,\n",
       "  36,\n",
       "  21,\n",
       "  26,\n",
       "  12,\n",
       "  44,\n",
       "  26,\n",
       "  15,\n",
       "  2,\n",
       "  19,\n",
       "  31,\n",
       "  16,\n",
       "  15,\n",
       "  15,\n",
       "  1,\n",
       "  15,\n",
       "  1,\n",
       "  60,\n",
       "  23,\n",
       "  1,\n",
       "  17,\n",
       "  11,\n",
       "  5,\n",
       "  5,\n",
       "  16,\n",
       "  23,\n",
       "  9,\n",
       "  1,\n",
       "  34,\n",
       "  64,\n",
       "  16,\n",
       "  1,\n",
       "  45,\n",
       "  3,\n",
       "  36,\n",
       "  34,\n",
       "  28,\n",
       "  11,\n",
       "  1,\n",
       "  1,\n",
       "  19,\n",
       "  1,\n",
       "  28,\n",
       "  20,\n",
       "  34,\n",
       "  34,\n",
       "  40,\n",
       "  11,\n",
       "  13,\n",
       "  11,\n",
       "  12,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  27,\n",
       "  1,\n",
       "  9,\n",
       "  15,\n",
       "  16,\n",
       "  1,\n",
       "  7,\n",
       "  1,\n",
       "  36,\n",
       "  2,\n",
       "  2,\n",
       "  21,\n",
       "  1,\n",
       "  16,\n",
       "  34,\n",
       "  25,\n",
       "  25,\n",
       "  4,\n",
       "  1,\n",
       "  12,\n",
       "  1,\n",
       "  6,\n",
       "  24,\n",
       "  9,\n",
       "  67,\n",
       "  30,\n",
       "  18,\n",
       "  16,\n",
       "  15,\n",
       "  25,\n",
       "  29,\n",
       "  30,\n",
       "  1,\n",
       "  52,\n",
       "  13,\n",
       "  44,\n",
       "  13,\n",
       "  16,\n",
       "  13,\n",
       "  13,\n",
       "  40,\n",
       "  1,\n",
       "  13,\n",
       "  16,\n",
       "  16,\n",
       "  14,\n",
       "  16,\n",
       "  3,\n",
       "  1,\n",
       "  18,\n",
       "  16,\n",
       "  61,\n",
       "  94,\n",
       "  13,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  61,\n",
       "  47,\n",
       "  43,\n",
       "  12,\n",
       "  45,\n",
       "  56,\n",
       "  1,\n",
       "  27,\n",
       "  19,\n",
       "  52,\n",
       "  24,\n",
       "  17,\n",
       "  48,\n",
       "  59,\n",
       "  36,\n",
       "  10,\n",
       "  1,\n",
       "  31,\n",
       "  16,\n",
       "  9,\n",
       "  22,\n",
       "  28,\n",
       "  8,\n",
       "  8,\n",
       "  37,\n",
       "  4,\n",
       "  31,\n",
       "  16,\n",
       "  28,\n",
       "  62,\n",
       "  16,\n",
       "  59,\n",
       "  4,\n",
       "  5,\n",
       "  15,\n",
       "  27,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  24,\n",
       "  4,\n",
       "  16,\n",
       "  27,\n",
       "  16,\n",
       "  6,\n",
       "  24,\n",
       "  38,\n",
       "  2,\n",
       "  16,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  51,\n",
       "  15,\n",
       "  22,\n",
       "  13,\n",
       "  6,\n",
       "  32,\n",
       "  6,\n",
       "  12,\n",
       "  13,\n",
       "  16,\n",
       "  6,\n",
       "  16,\n",
       "  1,\n",
       "  35,\n",
       "  16,\n",
       "  13,\n",
       "  5,\n",
       "  41,\n",
       "  72,\n",
       "  46,\n",
       "  16,\n",
       "  59,\n",
       "  58,\n",
       "  13,\n",
       "  1,\n",
       "  47,\n",
       "  94,\n",
       "  3,\n",
       "  57,\n",
       "  16,\n",
       "  1,\n",
       "  16,\n",
       "  41,\n",
       "  16,\n",
       "  21,\n",
       "  44,\n",
       "  16,\n",
       "  16,\n",
       "  44,\n",
       "  1,\n",
       "  2,\n",
       "  9,\n",
       "  26,\n",
       "  7,\n",
       "  6,\n",
       "  16,\n",
       "  23,\n",
       "  16,\n",
       "  2,\n",
       "  84,\n",
       "  84,\n",
       "  19,\n",
       "  27,\n",
       "  27,\n",
       "  46,\n",
       "  17,\n",
       "  35,\n",
       "  25,\n",
       "  1,\n",
       "  15,\n",
       "  25,\n",
       "  37,\n",
       "  60,\n",
       "  23,\n",
       "  12,\n",
       "  24,\n",
       "  33,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  21,\n",
       "  3,\n",
       "  41,\n",
       "  64,\n",
       "  23,\n",
       "  33,\n",
       "  1,\n",
       "  16,\n",
       "  27,\n",
       "  16,\n",
       "  28,\n",
       "  5,\n",
       "  46,\n",
       "  56,\n",
       "  12,\n",
       "  43,\n",
       "  16,\n",
       "  16,\n",
       "  8,\n",
       "  64,\n",
       "  16,\n",
       "  15,\n",
       "  38,\n",
       "  30,\n",
       "  33,\n",
       "  1,\n",
       "  57,\n",
       "  1,\n",
       "  26,\n",
       "  3,\n",
       "  34,\n",
       "  15,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  16,\n",
       "  11,\n",
       "  11,\n",
       "  5,\n",
       "  1,\n",
       "  16,\n",
       "  1,\n",
       "  55,\n",
       "  12,\n",
       "  30,\n",
       "  37,\n",
       "  16,\n",
       "  15,\n",
       "  16,\n",
       "  14,\n",
       "  61,\n",
       "  1,\n",
       "  42,\n",
       "  9,\n",
       "  17,\n",
       "  61,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  18,\n",
       "  2,\n",
       "  3,\n",
       "  6,\n",
       "  14,\n",
       "  3,\n",
       "  42,\n",
       "  19,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  19,\n",
       "  21,\n",
       "  3,\n",
       "  18,\n",
       "  16,\n",
       "  9,\n",
       "  26,\n",
       "  26,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  35,\n",
       "  28,\n",
       "  64,\n",
       "  13,\n",
       "  13,\n",
       "  24,\n",
       "  24,\n",
       "  18,\n",
       "  20,\n",
       "  8,\n",
       "  16,\n",
       "  1,\n",
       "  37,\n",
       "  57,\n",
       "  34,\n",
       "  40,\n",
       "  40,\n",
       "  9,\n",
       "  53,\n",
       "  9,\n",
       "  72,\n",
       "  10,\n",
       "  4,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  58,\n",
       "  16,\n",
       "  10,\n",
       "  79,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  18,\n",
       "  16,\n",
       "  16,\n",
       "  1,\n",
       "  11,\n",
       "  16,\n",
       "  14,\n",
       "  28,\n",
       "  28,\n",
       "  16,\n",
       "  56,\n",
       "  6,\n",
       "  40,\n",
       "  6,\n",
       "  73,\n",
       "  16,\n",
       "  54,\n",
       "  49,\n",
       "  52,\n",
       "  13,\n",
       "  16,\n",
       "  45,\n",
       "  16,\n",
       "  54,\n",
       "  16,\n",
       "  1,\n",
       "  1,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  43,\n",
       "  27,\n",
       "  43,\n",
       "  43,\n",
       "  33,\n",
       "  37,\n",
       "  1,\n",
       "  61,\n",
       "  4,\n",
       "  6,\n",
       "  47,\n",
       "  1,\n",
       "  5,\n",
       "  37,\n",
       "  8,\n",
       "  16,\n",
       "  8,\n",
       "  14,\n",
       "  5,\n",
       "  11,\n",
       "  20,\n",
       "  16,\n",
       "  62,\n",
       "  17,\n",
       "  19,\n",
       "  1,\n",
       "  61,\n",
       "  60,\n",
       "  33,\n",
       "  21,\n",
       "  45,\n",
       "  24,\n",
       "  6,\n",
       "  6,\n",
       "  16,\n",
       "  16,\n",
       "  22,\n",
       "  22,\n",
       "  6,\n",
       "  54,\n",
       "  6,\n",
       "  21,\n",
       "  13,\n",
       "  8,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  13,\n",
       "  23,\n",
       "  16,\n",
       "  17,\n",
       "  1,\n",
       "  35,\n",
       "  1,\n",
       "  17,\n",
       "  17,\n",
       "  1,\n",
       "  21,\n",
       "  22,\n",
       "  8,\n",
       "  8,\n",
       "  1,\n",
       "  1,\n",
       "  21,\n",
       "  58,\n",
       "  60,\n",
       "  16,\n",
       "  55,\n",
       "  32,\n",
       "  2,\n",
       "  16,\n",
       "  2,\n",
       "  1,\n",
       "  6,\n",
       "  23,\n",
       "  19,\n",
       "  1,\n",
       "  8,\n",
       "  21,\n",
       "  3,\n",
       "  21,\n",
       "  21,\n",
       "  13,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  37,\n",
       "  4,\n",
       "  1,\n",
       "  13,\n",
       "  57,\n",
       "  76,\n",
       "  36,\n",
       "  23,\n",
       "  1,\n",
       "  37,\n",
       "  9,\n",
       "  3,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  23,\n",
       "  2,\n",
       "  36,\n",
       "  1,\n",
       "  4,\n",
       "  23,\n",
       "  23,\n",
       "  3,\n",
       "  2,\n",
       "  36,\n",
       "  16,\n",
       "  109,\n",
       "  23,\n",
       "  2,\n",
       "  23,\n",
       "  6,\n",
       "  9,\n",
       "  27,\n",
       "  27,\n",
       "  7,\n",
       "  12,\n",
       "  22,\n",
       "  200,\n",
       "  1,\n",
       "  27,\n",
       "  9,\n",
       "  5,\n",
       "  14,\n",
       "  15,\n",
       "  43,\n",
       "  6,\n",
       "  36,\n",
       "  1,\n",
       "  24,\n",
       "  10,\n",
       "  5,\n",
       "  4,\n",
       "  30,\n",
       "  79,\n",
       "  16,\n",
       "  11,\n",
       "  29,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  11,\n",
       "  6,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  9,\n",
       "  33,\n",
       "  39,\n",
       "  55,\n",
       "  3,\n",
       "  10,\n",
       "  23,\n",
       "  23,\n",
       "  12,\n",
       "  47,\n",
       "  1,\n",
       "  11,\n",
       "  1,\n",
       "  16,\n",
       "  48,\n",
       "  1,\n",
       "  66,\n",
       "  1,\n",
       "  4,\n",
       "  46,\n",
       "  52,\n",
       "  33,\n",
       "  83,\n",
       "  30,\n",
       "  10,\n",
       "  5,\n",
       "  16,\n",
       "  16,\n",
       "  33,\n",
       "  3,\n",
       "  16,\n",
       "  29,\n",
       "  18,\n",
       "  26,\n",
       "  5,\n",
       "  30,\n",
       "  16,\n",
       "  26,\n",
       "  30,\n",
       "  24,\n",
       "  ...])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_tokens = []\n",
    "mask_indices = []\n",
    "y = []\n",
    "\n",
    "with open(tokens_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        entry = json.loads(line)\n",
    "        tokens = [int(tok) for tok in entry[\"tweet\"]]\n",
    "        tweet_tokens.append(tokens)\n",
    "        mask_indices.append(entry[\"mask_idx\"])\n",
    "        y.append(entry[\"stock_id\"])\n",
    "\n",
    "y, mask_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ac794d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[    6,     3,  8691,  ...,     4,     4,     4],\n",
       "         [13876,   354,    44,  ...,     4,     4,     4],\n",
       "         [ 9524,  1994,    56,  ...,     4,     4,     4],\n",
       "         ...,\n",
       "         [    6,     3,    16,  ...,     4,     4,     4],\n",
       "         [ 2009,   631,   856,  ...,     4,     4,     4],\n",
       "         [ 2009,   631,   856,  ...,     4,     4,     4]]),\n",
       " torch.Size([324063, 339]),\n",
       " tensor([ 0,  0,  0,  ..., 49, 49, 49]),\n",
       " torch.Size([324063]),\n",
       " tensor([ 1, 34, 14,  ...,  1, 38, 38]),\n",
       " torch.Size([324063]))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "max_len = max(len(tweet) for tweet in tweet_tokens)\n",
    "\n",
    "\n",
    "X = [tweet + [pad_id] * (max_len - len(tweet))\n",
    "    for tweet in tweet_tokens]\n",
    "\n",
    "\n",
    "X = torch.tensor(X, dtype=torch.long)\n",
    "y = torch.tensor(y, dtype=torch.long)\n",
    "mask_indices = torch.tensor(mask_indices, dtype=torch.long)\n",
    "\n",
    "X, X.shape, y, y.shape, mask_indices, mask_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0a00dff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: torch.Size([226844, 339]). y_train shape: torch.Size([226844])\n",
      "X_val shape: torch.Size([48609, 339]). y_val shape: torch.Size([48609])\n",
      "X_test shape: torch.Size([48610, 339]). y_test shape: torch.Size([48610])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([226844]), torch.Size([48609]), torch.Size([226844]))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_len = len(y)\n",
    "\n",
    "train_end = int(data_len * 0.7)\n",
    "val_end = int(data_len * 0.85)\n",
    "\n",
    "X_train, y_train, mask_train = X[ : train_end], y[ : train_end], mask_indices[ : train_end]\n",
    "X_val, y_val, mask_val = X[train_end : val_end], y[train_end : val_end], mask_indices[train_end : val_end]\n",
    "X_test, y_test, mask_test = X[val_end : ], y[val_end : ], mask_indices[val_end : ]\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}. y_train shape: {y_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}. y_val shape: {y_val.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}. y_test shape: {y_test.shape}\")\n",
    "\n",
    "mask_train.shape, mask_val.shape, mask_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7f0ae66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SLOTTokensDataset(Dataset):\n",
    "    def __init__(self, x, y, mask_idx):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.mask_idx = mask_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx], self.mask_idx[idx]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "929045c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([    6,     3,  8691,   202,   725,  8531,   202,    35,     9,     5,\n",
       "          3359,     6,  8046,   692,  1416,    35,     5,   168,     5,   498,\n",
       "             5,   258,     5,   979,  1033,     5,  2580,     5,  2210,     5,\n",
       "            99,     5,   234,     5,   110,     5, 11542,    75,     5,   369,\n",
       "             4,     4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "             4,     4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "             4,     4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "             4,     4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "             4,     4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "             4,     4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "             4,     4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "             4,     4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "             4,     4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "             4,     4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "             4,     4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "             4,     4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "             4,     4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "             4,     4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "             4,     4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "             4,     4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "             4,     4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "             4,     4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "             4,     4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "             4,     4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "             4,     4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "             4,     4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "             4,     4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "             4,     4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "             4,     4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "             4,     4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "             4,     4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "             4,     4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "             4,     4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "             4,     4,     4,     4,     4,     4,     4,     4,     4]),\n",
       " tensor(0),\n",
       " tensor(1))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = SLOTTokensDataset(X_train, y_train, mask_train)\n",
    "val_dataset = SLOTTokensDataset(X_val, y_val, mask_val)\n",
    "test_dataset = SLOTTokensDataset(X_test, y_test, mask_test)\n",
    "\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b56b0f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087eca54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class StockIdentification:\n",
    "    def __init__(self, num_stocks, embd_size, hidden_size, vocab_size):\n",
    "    \n",
    "        \n",
    "\n",
    "        self.stock_embd = nn.Embedding(num_embeddings=num_stocks, embedding_dim=2*hidden_size)\n",
    "        \n",
    "        \n",
    "        self.token_embd = nn.Embedding(num_embeddings=vocab_size,\n",
    "                                       embedding_dim=embd_size,\n",
    "                                       padding_idx=pad_id)\n",
    "        \n",
    "\n",
    "        self.bi_lstm = nn.LSTM(\n",
    "            input_size=embd_size, \n",
    "            hidden_size=hidden_size,\n",
    "            bidirectional=True,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self, x, mask_idx):\n",
    "        # x: (B, T)\n",
    "        # mask_idx: (B,). The index of the <MASK> token for each tweet\n",
    "        batch_size = x.size(0)\n",
    "        token_embs = self.token_embd(x) # (B, T, embd_size)\n",
    "\n",
    "\n",
    "        # output: (B, T, 2*hidden_size)\n",
    "        # h_n, c_n : (2*num_layers, B, hidden_size)\n",
    "        output, h_n, c_n = self.bi_lstm(token_embs)\n",
    "\n",
    "        h_e = output[torch.arange(batch_size), mask_idx] # (B, 2*hidden_size)\n",
    "\n",
    "        stock_embs = self.stock_embd.weight # (num_stocks, 2*hidden_size)\n",
    "        logits = torch.matmul(h_e, stock_embs.T) #  (B, 2*hidden_size) @ (2*hidden_size, num_stocks) -> (B, num_stocks)\n",
    "        \n",
    "\n",
    "        return logits\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31710ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def calculate_loss(logits, stock_labels):\n",
    "    # stock_labels: (B,)\n",
    "    log_probs = F.log_softmax(logits, dim=1)  # (B, num_stocks)\n",
    "\n",
    "    true_log_probs = log_probs[torch.arange(logits.size(0)), stock_labels] # (B,)\n",
    "\n",
    "    loss = -true_log_probs.sum()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa230b5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stock-lstm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
